{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9926676,"sourceType":"datasetVersion","datasetId":6095429}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:07:21.900412Z","iopub.execute_input":"2024-11-17T02:07:21.900795Z","iopub.status.idle":"2024-11-17T02:09:33.549748Z","shell.execute_reply.started":"2024-11-17T02:07:21.900731Z","shell.execute_reply":"2024-11-17T02:09:33.548780Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip3-autoremove in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from pip3-autoremove) (24.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pip3-autoremove) (70.0.0)\ndill 0.3.8 is installed but dill<0.3.2,>=0.3.1.1 is required\nRedoing requirement with just package name...\ncloudpickle 3.0.0 is installed but cloudpickle~=2.2.1 is required\nRedoing requirement with just package name...\nnumpy 1.26.4 is installed but numpy<1.25.0,>=1.14.3 is required\nRedoing requirement with just package name...\npyarrow 16.1.0 is installed but pyarrow<10.0.0,>=3.0.0 is required\nRedoing requirement with just package name...\njupyterlab 4.2.5 is installed but jupyterlab~=3.6.0 is required\nRedoing requirement with just package name...\ngoogle-cloud-bigquery 2.34.4 is installed but google-cloud-bigquery[bqstorage,pandas]>=3.10.0 is required\nRedoing requirement with just package name...\ngoogle-cloud-storage 1.44.0 is installed but google-cloud-storage>=2.0.0 is required\nRedoing requirement with just package name...\npandas 2.2.2 is installed but pandas<2.1.4,>=1.5.0 is required\nRedoing requirement with just package name...\nbotocore 1.35.23 is installed but botocore<1.30.0,>=1.29.100 is required\nRedoing requirement with just package name...\nnumpy 1.26.4 is installed but numpy<3.0,>=2.0 is required\nRedoing requirement with just package name...\ngoogle-api-python-client 2.147.0 is installed but google-api-python-client==1.8.0 is required\nRedoing requirement with just package name...\npackaging 21.3 is installed but packaging>=23.0 is required\nRedoing requirement with just package name...\nThe 'cubinlinker' distribution was not found and is required by the application\nSkipping cubinlinker\ncuda-python 12.6.0 is installed but cuda-python<12.0a0,>=11.7.1 is required\nRedoing requirement with just package name...\nThe 'cupy-cuda11x>=12.0.0' distribution was not found and is required by the application\nSkipping cupy-cuda11x\nThe 'ptxcompiler' distribution was not found and is required by the application\nSkipping ptxcompiler\nThe 'cupy-cuda11x>=12.0.0' distribution was not found and is required by the application\nSkipping cupy-cuda11x\nThe 'cupy-cuda11x>=12.0.0' distribution was not found and is required by the application\nSkipping cupy-cuda11x\npydantic 2.9.2 is installed but pydantic~=1.10.0 is required\nRedoing requirement with just package name...\ndask 2024.9.1 is installed but dask==2024.7.1 is required\nRedoing requirement with just package name...\nThe 'google.auth>=1.14.1' distribution was not found and is required by the application\nSkipping google.auth\ntorch 2.5.1+cu121 is installed but torch<2.5,>=1.10 is required\nRedoing requirement with just package name...\nscipy 1.14.1 is installed but scipy<1.14.0,>=1.7.0 is required\nRedoing requirement with just package name...\ngoogle-api-core 2.11.1 is installed but google-api-core[grpc]<2.0.0dev,>=1.22.2 is required\nRedoing requirement with just package name...\ngoogle-api-core 2.11.1 is installed but google-api-core[grpc]<2.0.0dev,>=1.14.0 is required\nRedoing requirement with just package name...\npyarrow 16.1.0 is installed but pyarrow<15,>=2 is required\nRedoing requirement with just package name...\njupyter-lsp 1.5.1 is installed but jupyter-lsp>=2.0.0 is required\nRedoing requirement with just package name...\njupyter-lsp 1.5.1 is installed but jupyter-lsp>=2.0.0 is required\nRedoing requirement with just package name...\ngoogle-cloud-storage 1.44.0 is installed but google-cloud-storage<3,>=2.2.1 is required\nRedoing requirement with just package name...\npackaging 21.3 is installed but packaging>=22 is required\nRedoing requirement with just package name...\nShapely 1.8.5.post1 is installed but shapely>=2.0.1 is required\nRedoing requirement with just package name...\ndill 0.3.8 is installed but dill>=0.3.9 is required\nRedoing requirement with just package name...\nmultiprocess 0.70.16 is installed but multiprocess>=0.70.17 is required\nRedoing requirement with just package name...\npackaging 21.3 is installed but packaging>=23.2 is required\nRedoing requirement with just package name...\ndask 2024.9.1 is installed but dask==2024.7.1 is required\nRedoing requirement with just package name...\ncuda-python 12.6.0 is installed but cuda-python<12.0a0,>=11.7.1 is required\nRedoing requirement with just package name...\nnltk 3.2.4 is installed but nltk>=3.8 is required\nRedoing requirement with just package name...\nThe 'libucx>=1.15.0' distribution was not found and is required by the application\nSkipping libucx\npackaging 21.3 is installed but packaging>=23.1 is required\nRedoing requirement with just package name...\nscipy 1.14.1 is installed but scipy<1.14,>=1.4.1 is required\nRedoing requirement with just package name...\ntorch 2.5.1+cu121 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cuda-nvrtc-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cuda-runtime-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cuda-cupti-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cudnn-cu12 9.1.0.70 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cublas-cu12 12.1.3.1 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cufft-cu12 11.0.2.54 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-curand-cu12 10.3.2.106 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-cusolver-cu12 11.4.5.107 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-nvjitlink-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cusparse-cu12 12.1.0.106 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-nccl-cu12 2.21.5 (/opt/conda/lib/python3.10/site-packages)\n    nvidia-nvtx-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n    sympy 1.13.1 (/opt/conda/lib/python3.10/site-packages)\n        mpmath 1.3.0 (/opt/conda/lib/python3.10/site-packages)\ntorchvision 0.20.1+cu121 (/opt/conda/lib/python3.10/site-packages)\n    torch 2.5.1+cu121 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-nvrtc-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-runtime-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-cupti-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cudnn-cu12 9.1.0.70 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-cublas-cu12 12.1.3.1 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cufft-cu12 11.0.2.54 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-curand-cu12 10.3.2.106 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cusolver-cu12 11.4.5.107 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-nvjitlink-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-cusparse-cu12 12.1.0.106 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-nccl-cu12 2.21.5 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-nvtx-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        sympy 1.13.1 (/opt/conda/lib/python3.10/site-packages)\n            mpmath 1.3.0 (/opt/conda/lib/python3.10/site-packages)\ntorchaudio 2.5.1+cu121 (/opt/conda/lib/python3.10/site-packages)\n    torch 2.5.1+cu121 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-nvrtc-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-runtime-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cuda-cupti-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cudnn-cu12 9.1.0.70 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-cublas-cu12 12.1.3.1 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cufft-cu12 11.0.2.54 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-curand-cu12 10.3.2.106 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-cusolver-cu12 11.4.5.107 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-nvjitlink-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n            nvidia-cusparse-cu12 12.1.0.106 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-nccl-cu12 2.21.5 (/opt/conda/lib/python3.10/site-packages)\n        nvidia-nvtx-cu12 12.1.105 (/opt/conda/lib/python3.10/site-packages)\n        sympy 1.13.1 (/opt/conda/lib/python3.10/site-packages)\n            mpmath 1.3.0 (/opt/conda/lib/python3.10/site-packages)\nFound existing installation: torchaudio 2.5.1+cu121\nUninstalling torchaudio-2.5.1+cu121:\n  Successfully uninstalled torchaudio-2.5.1+cu121\nFound existing installation: nvidia-nvtx-cu12 12.1.105\nUninstalling nvidia-nvtx-cu12-12.1.105:\n  Successfully uninstalled nvidia-nvtx-cu12-12.1.105\nFound existing installation: nvidia-cuda-cupti-cu12 12.1.105\nUninstalling nvidia-cuda-cupti-cu12-12.1.105:\n  Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\nFound existing installation: nvidia-nccl-cu12 2.21.5\nUninstalling nvidia-nccl-cu12-2.21.5:\n  Successfully uninstalled nvidia-nccl-cu12-2.21.5\nFound existing installation: mpmath 1.3.0\nUninstalling mpmath-1.3.0:\n  Successfully uninstalled mpmath-1.3.0\nFound existing installation: nvidia-cublas-cu12 12.1.3.1\nUninstalling nvidia-cublas-cu12-12.1.3.1:\n  Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\nFound existing installation: nvidia-cudnn-cu12 9.1.0.70\nUninstalling nvidia-cudnn-cu12-9.1.0.70:\n  Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\nFound existing installation: torchvision 0.20.1+cu121\nUninstalling torchvision-0.20.1+cu121:\n  Successfully uninstalled torchvision-0.20.1+cu121\nFound existing installation: sympy 1.13.1\nUninstalling sympy-1.13.1:\n  Successfully uninstalled sympy-1.13.1\nFound existing installation: nvidia-cusparse-cu12 12.1.0.106\nUninstalling nvidia-cusparse-cu12-12.1.0.106:\n  Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\nFound existing installation: torch 2.5.1+cu121\nUninstalling torch-2.5.1+cu121:\n  Successfully uninstalled torch-2.5.1+cu121\nFound existing installation: nvidia-curand-cu12 10.3.2.106\nUninstalling nvidia-curand-cu12-10.3.2.106:\n  Successfully uninstalled nvidia-curand-cu12-10.3.2.106\nFound existing installation: nvidia-cufft-cu12 11.0.2.54\nUninstalling nvidia-cufft-cu12-11.0.2.54:\n  Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\nFound existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\nUninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n  Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\nFound existing installation: nvidia-cuda-runtime-cu12 12.1.105\nUninstalling nvidia-cuda-runtime-cu12-12.1.105:\n  Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\nFound existing installation: nvidia-cusolver-cu12 11.4.5.107\nUninstalling nvidia-cusolver-cu12-11.4.5.107:\n  Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\nFound existing installation: nvidia-nvjitlink-cu12 12.1.105\nUninstalling nvidia-nvjitlink-cu12-12.1.105:\n  Successfully uninstalled nvidia-nvjitlink-cu12-12.1.105\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch\n  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\nCollecting torchvision\n  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\nCollecting torchaudio\n  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\nRequirement already satisfied: xformers in /opt/conda/lib/python3.10/site-packages (0.0.28.post3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nRequirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.0)\nCollecting sympy==1.13.1 (from torch)\n  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n  Using cached https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\nRequirement already satisfied: unsloth in /opt/conda/lib/python3.10/site-packages (2024.11.7)\nRequirement already satisfied: unsloth-zoo>=2024.11.1 in /opt/conda/lib/python3.10/site-packages (from unsloth) (2024.11.5)\nRequirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (2.5.1+cu121)\nRequirement already satisfied: xformers>=0.0.27.post2 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.0.28.post3)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.44.1)\nRequirement already satisfied: triton>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.1.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth) (21.3)\nRequirement already satisfied: tyro in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.8.14)\nRequirement already satisfied: transformers>=4.46.1 in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.46.2)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.0.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.34.2)\nRequirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.12.1)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.13.2)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.25.1)\nRequirement already satisfied: hf-transfer in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.1.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\nRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth) (12.1.105)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.1->unsloth) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.1->unsloth) (0.20.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.7.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (1.7.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n    \"unsloth/Phi-3-medium-4k-instruct\",\n    \"unsloth/gemma-2-9b-bnb-4bit\",\n    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n\n    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:09:33.551204Z","iopub.execute_input":"2024-11-17T02:09:33.551526Z","iopub.status.idle":"2024-11-17T02:09:58.142032Z","shell.execute_reply.started":"2024-11-17T02:09:33.551493Z","shell.execute_reply":"2024-11-17T02:09:58.141114Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:09:58.145925Z","iopub.execute_input":"2024-11-17T02:09:58.146920Z","iopub.status.idle":"2024-11-17T02:10:03.391533Z","shell.execute_reply.started":"2024-11-17T02:09:58.146866Z","shell.execute_reply":"2024-11-17T02:10:03.390681Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2024.11.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom unsloth.chat_templates import get_chat_template, standardize_sharegpt\nfrom datasets import load_dataset\nfrom datasets import Dataset\n# Load your dataset from the CSV file\ndf = pd.read_csv(\"/kaggle/input/iiitn-disha/iiitn.csv\")\n\n# Transform each row into a conversation format\ndf['conversations'] = df.apply(lambda row: [\n    {\"from\": \"human\", \"value\": row['Name']},\n    {\"from\": \"gpt\", \"value\": row['Details']}\n], axis=1)\n\n# Select only the `conversations` column\ndf = df[['conversations']]\n\n# Convert the modified DataFrame to a Hugging Face Dataset\ndataset = Dataset.from_pandas(df)\n\n# Verify the structure of the dataset\nprint(dataset[0])  # Print the first item to see the format\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:03.392701Z","iopub.execute_input":"2024-11-17T02:10:03.392998Z","iopub.status.idle":"2024-11-17T02:10:03.437837Z","shell.execute_reply.started":"2024-11-17T02:10:03.392965Z","shell.execute_reply":"2024-11-17T02:10:03.436892Z"}},"outputs":[{"name":"stdout","text":"{'conversations': [{'from': 'human', 'value': 'cse_Dr_Prerna_Mishra'}, {'from': 'gpt', 'value': '{\\n\"name\": \"Dr Prerna Mishra\",\\n\"department\": \"Computer Science and Engineering\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"phone_no\": \"9834485669\",\\n\"email\": \"pmishra@iiitn.ac.in\",\\n\"joining_date\": \"03-01-2023\",\\n\"education\": [],\\n\"teaching_experience\": [\\n{\\n\"institution\": \"Indian Institute of Information Technology Nagpur\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"start_date\": \"03-01-2023\",\\n\"end_date\": \"NA\"\\n}\\n],\\n\"industrial_experience\": [],\\n\"laboratory_development\": [],\\n\"areas_of_interest\": [],\\n\"projects\": [],\\n\"publications\": {},\\n\"supervision\": {\\n\"pg_dissertation\": \"NA\",\\n\"ug_dissertation\": \"NA\",\\n\"phd_dissertation\": \"NA\",\\n\"mtech_dissertation\": \"NA\"},\\n\"fellowships\": []\\n}'}]}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\npass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:03.438994Z","iopub.execute_input":"2024-11-17T02:10:03.439304Z","iopub.status.idle":"2024-11-17T02:10:03.446071Z","shell.execute_reply.started":"2024-11-17T02:10:03.439269Z","shell.execute_reply":"2024-11-17T02:10:03.445136Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from unsloth.chat_templates import standardize_sharegpt\ndataset = standardize_sharegpt(dataset)\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:03.447262Z","iopub.execute_input":"2024-11-17T02:10:03.447552Z","iopub.status.idle":"2024-11-17T02:10:03.796432Z","shell.execute_reply.started":"2024-11-17T02:10:03.447519Z","shell.execute_reply":"2024-11-17T02:10:03.795548Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Standardizing format:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea54eb5bd0844c80884ac1b45db863d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d1e50f338c44ce79749714d76ad9189"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dataset[5][\"conversations\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:03.797878Z","iopub.execute_input":"2024-11-17T02:10:03.798532Z","iopub.status.idle":"2024-11-17T02:10:03.806717Z","shell.execute_reply.started":"2024-11-17T02:10:03.798484Z","shell.execute_reply":"2024-11-17T02:10:03.805764Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'content': 'cse_Ms._Madhuri_Dubey', 'role': 'user'},\n {'content': '{\\n\"name\": \"Ms. Madhuri Dubey\",\\n\"department\": \"Computer Science and Engineering\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"phone_no\": \"9637073939\",\\n\"email\": \"mdubey@iiitn.ac.in\",\\n\"joining_date\": \"10-07-2023\",\\n\"education\": [\\n{\\n\"degree_year\": \"2012\",\\n\"degree\": \"U.G.\",\\n\"college_name\": \"RTMNU\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2014\",\\n\"degree\": \"P.G.\",\\n\"college_name\": \"GHRCE\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2024\",\\n\"degree\": \"PH.D\",\\n\"college_name\": \"IIIT NAGPUR\",\\n\"university\": \"IIIT\"\\n}],\\n\"teaching_experience\": [\\n{\\n\"institution\": \"Indian Institute of Information Technology Nagpur\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"start_date\": \"10-07-2023\",\\n\"end_date\": \"NA\"\\n}\\n],\\n\"industrial_experience\": [],\\n\"laboratory_development\": [],\\n\"areas_of_interest\": [],\\n\"projects\": [\\n{\\n\"title\": \"Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Event management system\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Neural Cryptography for Secret Key Exchange\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Implementation of Event Planner\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Review of optimised fusion Techniques in human computer\\ninteraction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Improving coronary heart disease prediction with real-life\\ndataset: a stacked generalization framework with maximum clinical attributes and SMOTE\\nbalancing for imbalanced data\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"A Survey Paper on Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n}\\n],\\n\"publications\": {\\n\"0\": \"Group Message Privacy and Data Sharing\",\\n\"1\": \"Event management system\",\\n\"2\": \"Neural Cryptography for Secret Key Exchange\",\\n\"3\": \"Implementation of Event Planner\",\\n\"4\": \"Review of optimised fusion Techniques in human computer interaction\",\\n\"5\": \"Improving coronary heart disease prediction with real-life dataset: a\\nstacked generalization framework with maximum clinical attributes and SMOTE balancing\\nfor imbalanced data\",\\n\"6\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"7\": \"A Survey Paper on Group Message Privacy and Data Sharing\"\\n},\\n\"supervision\": {\\n\"pg_dissertation\": \"NA\",\\n\"ug_dissertation\": \"NA\",\\n\"phd_dissertation\": \"NA\",\\n\"mtech_dissertation\": \"NA\"\\n},\\n\"fellowships\": []\\n}',\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 4,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run.\n        num_train_epochs=50,\n        learning_rate = 0.001,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use this for WandB etc\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:03.807927Z","iopub.execute_input":"2024-11-17T02:10:03.808251Z","iopub.status.idle":"2024-11-17T02:10:06.179578Z","shell.execute_reply.started":"2024-11-17T02:10:03.808204Z","shell.execute_reply":"2024-11-17T02:10:06.178509Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3fe14955e8e44d1bbbe87ecfffdc6da"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:06.181213Z","iopub.execute_input":"2024-11-17T02:10:06.181606Z","iopub.status.idle":"2024-11-17T02:10:06.415227Z","shell.execute_reply.started":"2024-11-17T02:10:06.181560Z","shell.execute_reply":"2024-11-17T02:10:06.414315Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9705d1074d4c6e9a148133854ab3f5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:06.416699Z","iopub.execute_input":"2024-11-17T02:10:06.417109Z","iopub.status.idle":"2024-11-17T02:10:06.436990Z","shell.execute_reply.started":"2024-11-17T02:10:06.417054Z","shell.execute_reply":"2024-11-17T02:10:06.436045Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\ncse_Ms._Madhuri_Dubey<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{\\n\"name\": \"Ms. Madhuri Dubey\",\\n\"department\": \"Computer Science and Engineering\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"phone_no\": \"9637073939\",\\n\"email\": \"mdubey@iiitn.ac.in\",\\n\"joining_date\": \"10-07-2023\",\\n\"education\": [\\n{\\n\"degree_year\": \"2012\",\\n\"degree\": \"U.G.\",\\n\"college_name\": \"RTMNU\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2014\",\\n\"degree\": \"P.G.\",\\n\"college_name\": \"GHRCE\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2024\",\\n\"degree\": \"PH.D\",\\n\"college_name\": \"IIIT NAGPUR\",\\n\"university\": \"IIIT\"\\n}],\\n\"teaching_experience\": [\\n{\\n\"institution\": \"Indian Institute of Information Technology Nagpur\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"start_date\": \"10-07-2023\",\\n\"end_date\": \"NA\"\\n}\\n],\\n\"industrial_experience\": [],\\n\"laboratory_development\": [],\\n\"areas_of_interest\": [],\\n\"projects\": [\\n{\\n\"title\": \"Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Event management system\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Neural Cryptography for Secret Key Exchange\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Implementation of Event Planner\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Review of optimised fusion Techniques in human computer\\ninteraction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Improving coronary heart disease prediction with real-life\\ndataset: a stacked generalization framework with maximum clinical attributes and SMOTE\\nbalancing for imbalanced data\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"A Survey Paper on Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n}\\n],\\n\"publications\": {\\n\"0\": \"Group Message Privacy and Data Sharing\",\\n\"1\": \"Event management system\",\\n\"2\": \"Neural Cryptography for Secret Key Exchange\",\\n\"3\": \"Implementation of Event Planner\",\\n\"4\": \"Review of optimised fusion Techniques in human computer interaction\",\\n\"5\": \"Improving coronary heart disease prediction with real-life dataset: a\\nstacked generalization framework with maximum clinical attributes and SMOTE balancing\\nfor imbalanced data\",\\n\"6\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"7\": \"A Survey Paper on Group Message Privacy and Data Sharing\"\\n},\\n\"supervision\": {\\n\"pg_dissertation\": \"NA\",\\n\"ug_dissertation\": \"NA\",\\n\"phd_dissertation\": \"NA\",\\n\"mtech_dissertation\": \"NA\"\\n},\\n\"fellowships\": []\\n}<|eot_id|>'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\ntokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:06.438070Z","iopub.execute_input":"2024-11-17T02:10:06.438374Z","iopub.status.idle":"2024-11-17T02:10:06.462524Z","shell.execute_reply.started":"2024-11-17T02:10:06.438343Z","shell.execute_reply":"2024-11-17T02:10:06.461648Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'                                             \\n\\n{\\n\"name\": \"Ms. Madhuri Dubey\",\\n\"department\": \"Computer Science and Engineering\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"phone_no\": \"9637073939\",\\n\"email\": \"mdubey@iiitn.ac.in\",\\n\"joining_date\": \"10-07-2023\",\\n\"education\": [\\n{\\n\"degree_year\": \"2012\",\\n\"degree\": \"U.G.\",\\n\"college_name\": \"RTMNU\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2014\",\\n\"degree\": \"P.G.\",\\n\"college_name\": \"GHRCE\",\\n\"university\": \"RTMNU\"\\n},\\n{\\n\"degree_year\": \"2024\",\\n\"degree\": \"PH.D\",\\n\"college_name\": \"IIIT NAGPUR\",\\n\"university\": \"IIIT\"\\n}],\\n\"teaching_experience\": [\\n{\\n\"institution\": \"Indian Institute of Information Technology Nagpur\",\\n\"position\": \"Adjunct Assistant Professor\",\\n\"start_date\": \"10-07-2023\",\\n\"end_date\": \"NA\"\\n}\\n],\\n\"industrial_experience\": [],\\n\"laboratory_development\": [],\\n\"areas_of_interest\": [],\\n\"projects\": [\\n{\\n\"title\": \"Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Event management system\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Neural Cryptography for Secret Key Exchange\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Implementation of Event Planner\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Review of optimised fusion Techniques in human computer\\ninteraction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Improving coronary heart disease prediction with real-life\\ndataset: a stacked generalization framework with maximum clinical attributes and SMOTE\\nbalancing for imbalanced data\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\\n\"funding_amount\": \"NA\"\\n},\\n{\\n\"title\": \"A Survey Paper on Group Message Privacy and Data Sharing\",\\n\"funding_agency\": \"NA\",\\n\"role\": \"NA\",\\n\"start_date\": \"NA\",\\n\"end_date\": \"NA\",\"funding_amount\": \"NA\"\\n}\\n],\\n\"publications\": {\\n\"0\": \"Group Message Privacy and Data Sharing\",\\n\"1\": \"Event management system\",\\n\"2\": \"Neural Cryptography for Secret Key Exchange\",\\n\"3\": \"Implementation of Event Planner\",\\n\"4\": \"Review of optimised fusion Techniques in human computer interaction\",\\n\"5\": \"Improving coronary heart disease prediction with real-life dataset: a\\nstacked generalization framework with maximum clinical attributes and SMOTE balancing\\nfor imbalanced data\",\\n\"6\": \"Eye and Speech Fusion in Human Computer Interaction\",\\n\"7\": \"A Survey Paper on Group Message Privacy and Data Sharing\"\\n},\\n\"supervision\": {\\n\"pg_dissertation\": \"NA\",\\n\"ug_dissertation\": \"NA\",\\n\"phd_dissertation\": \"NA\",\\n\"mtech_dissertation\": \"NA\"\\n},\\n\"fellowships\": []\\n}<|eot_id|>'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:06.468171Z","iopub.execute_input":"2024-11-17T02:10:06.468548Z","iopub.status.idle":"2024-11-17T02:10:06.474882Z","shell.execute_reply.started":"2024-11-17T02:10:06.468514Z","shell.execute_reply":"2024-11-17T02:10:06.473928Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n2.635 GB of memory reserved.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T02:10:06.476127Z","iopub.execute_input":"2024-11-17T02:10:06.476417Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 222 | Num Epochs = 50\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 16 | Total steps = 700\n \"-____-\"     Number of trainable parameters = 24,313,856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='697' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [697/700 3:51:09 < 00:59, 0.05 it/s, Epoch 49.71/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.442300</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.649500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.557800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.480200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.347800</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.184600</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.318700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.332100</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.098800</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.136500</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.279300</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.387700</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.226600</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.103800</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.886900</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.968500</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.039100</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.250600</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.773200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.135600</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.762400</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.982600</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.786300</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.015300</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.011500</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.306500</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.705500</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.920700</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.803700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.843600</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.626200</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.616100</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.733700</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.680100</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.648500</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.553800</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.606500</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.643700</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.706700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.861000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.559200</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.760400</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.577300</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.550300</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.429500</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.482800</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.477000</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.481500</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.473600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.415300</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.530600</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.413200</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.458600</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.384200</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.527400</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.356600</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.211900</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.443300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.341900</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.309000</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.324700</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.256900</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.272000</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.331500</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.255900</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.292700</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.318600</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.289400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.275500</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.173700</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.272100</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.097100</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.138500</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.235300</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.184300</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.185300</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.145600</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.233100</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.214000</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.146900</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.323800</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.235800</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.192100</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.112300</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.130000</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.099900</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.102900</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.096800</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.109100</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.083000</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.115500</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.117400</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.094500</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.211100</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.164100</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.142300</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.133600</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.073200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.073300</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>0.085000</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>0.073300</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>0.068000</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>0.195200</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.105000</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>0.082500</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0.094200</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>0.061400</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0.105600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.072900</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>0.122100</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>0.095300</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>0.066600</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>0.104400</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.044800</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>0.041300</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>0.059000</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>0.078000</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>0.054500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.054000</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>0.062100</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>0.043500</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>0.063300</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>0.088400</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.077300</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>0.051300</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>0.037000</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>0.026100</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>0.037100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.041500</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>0.035000</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>0.048400</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>0.040100</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>0.122500</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.041400</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>0.030600</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>0.041100</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>0.045600</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>0.034500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.036500</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>0.025500</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>0.113200</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>0.021800</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>0.028400</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.029800</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>0.035800</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>0.021800</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>0.024800</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>0.036600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.029000</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>0.030300</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>0.075900</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>0.037600</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>0.035100</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.014800</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>0.021200</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>0.017700</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>0.018200</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>0.013600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.032800</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>0.031900</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>0.051300</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>0.031000</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>0.013100</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.031500</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0.026900</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>0.025000</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>0.029400</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>0.012800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.013600</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>0.018700</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>0.017500</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>0.017300</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>0.012000</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.017200</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0.019400</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>0.018100</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>0.030900</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>0.019900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.021900</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>0.019700</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>0.018200</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>0.009600</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>0.014500</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.010400</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>0.017500</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>0.014600</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.010000</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>0.009600</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>0.014600</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0.012100</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>0.018900</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.025900</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>0.014100</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>0.005300</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>0.010400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.005200</td>\n    </tr>\n    <tr>\n      <td>201</td>\n      <td>0.009700</td>\n    </tr>\n    <tr>\n      <td>202</td>\n      <td>0.008500</td>\n    </tr>\n    <tr>\n      <td>203</td>\n      <td>0.013100</td>\n    </tr>\n    <tr>\n      <td>204</td>\n      <td>0.010600</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.014900</td>\n    </tr>\n    <tr>\n      <td>206</td>\n      <td>0.013000</td>\n    </tr>\n    <tr>\n      <td>207</td>\n      <td>0.009600</td>\n    </tr>\n    <tr>\n      <td>208</td>\n      <td>0.012100</td>\n    </tr>\n    <tr>\n      <td>209</td>\n      <td>0.014400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.010400</td>\n    </tr>\n    <tr>\n      <td>211</td>\n      <td>0.007100</td>\n    </tr>\n    <tr>\n      <td>212</td>\n      <td>0.006700</td>\n    </tr>\n    <tr>\n      <td>213</td>\n      <td>0.008500</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>0.005000</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>0.006800</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0.008900</td>\n    </tr>\n    <tr>\n      <td>219</td>\n      <td>0.008400</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.004100</td>\n    </tr>\n    <tr>\n      <td>221</td>\n      <td>0.005800</td>\n    </tr>\n    <tr>\n      <td>222</td>\n      <td>0.010200</td>\n    </tr>\n    <tr>\n      <td>223</td>\n      <td>0.006700</td>\n    </tr>\n    <tr>\n      <td>224</td>\n      <td>0.012500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>226</td>\n      <td>0.004100</td>\n    </tr>\n    <tr>\n      <td>227</td>\n      <td>0.005000</td>\n    </tr>\n    <tr>\n      <td>228</td>\n      <td>0.004600</td>\n    </tr>\n    <tr>\n      <td>229</td>\n      <td>0.002900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.008400</td>\n    </tr>\n    <tr>\n      <td>231</td>\n      <td>0.003400</td>\n    </tr>\n    <tr>\n      <td>232</td>\n      <td>0.008300</td>\n    </tr>\n    <tr>\n      <td>233</td>\n      <td>0.008500</td>\n    </tr>\n    <tr>\n      <td>234</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>236</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>237</td>\n      <td>0.013500</td>\n    </tr>\n    <tr>\n      <td>238</td>\n      <td>0.007000</td>\n    </tr>\n    <tr>\n      <td>239</td>\n      <td>0.002300</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.004200</td>\n    </tr>\n    <tr>\n      <td>241</td>\n      <td>0.003300</td>\n    </tr>\n    <tr>\n      <td>242</td>\n      <td>0.003200</td>\n    </tr>\n    <tr>\n      <td>243</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>244</td>\n      <td>0.006100</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>246</td>\n      <td>0.006000</td>\n    </tr>\n    <tr>\n      <td>247</td>\n      <td>0.006000</td>\n    </tr>\n    <tr>\n      <td>248</td>\n      <td>0.004100</td>\n    </tr>\n    <tr>\n      <td>249</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.005300</td>\n    </tr>\n    <tr>\n      <td>251</td>\n      <td>0.004400</td>\n    </tr>\n    <tr>\n      <td>252</td>\n      <td>0.011000</td>\n    </tr>\n    <tr>\n      <td>253</td>\n      <td>0.002000</td>\n    </tr>\n    <tr>\n      <td>254</td>\n      <td>0.002000</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.003500</td>\n    </tr>\n    <tr>\n      <td>256</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>257</td>\n      <td>0.002100</td>\n    </tr>\n    <tr>\n      <td>258</td>\n      <td>0.002900</td>\n    </tr>\n    <tr>\n      <td>259</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>261</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>262</td>\n      <td>0.002700</td>\n    </tr>\n    <tr>\n      <td>263</td>\n      <td>0.003400</td>\n    </tr>\n    <tr>\n      <td>264</td>\n      <td>0.003500</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>266</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>267</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>268</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>269</td>\n      <td>0.003600</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.002700</td>\n    </tr>\n    <tr>\n      <td>271</td>\n      <td>0.001900</td>\n    </tr>\n    <tr>\n      <td>272</td>\n      <td>0.001900</td>\n    </tr>\n    <tr>\n      <td>273</td>\n      <td>0.004800</td>\n    </tr>\n    <tr>\n      <td>274</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.003700</td>\n    </tr>\n    <tr>\n      <td>276</td>\n      <td>0.005200</td>\n    </tr>\n    <tr>\n      <td>277</td>\n      <td>0.002200</td>\n    </tr>\n    <tr>\n      <td>278</td>\n      <td>0.003100</td>\n    </tr>\n    <tr>\n      <td>279</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <td>281</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>282</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>283</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>284</td>\n      <td>0.001500</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>286</td>\n      <td>0.007400</td>\n    </tr>\n    <tr>\n      <td>287</td>\n      <td>0.002100</td>\n    </tr>\n    <tr>\n      <td>288</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>289</td>\n      <td>0.002200</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.003100</td>\n    </tr>\n    <tr>\n      <td>291</td>\n      <td>0.002000</td>\n    </tr>\n    <tr>\n      <td>292</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>293</td>\n      <td>0.002700</td>\n    </tr>\n    <tr>\n      <td>294</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>296</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>297</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <td>298</td>\n      <td>0.004200</td>\n    </tr>\n    <tr>\n      <td>299</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>301</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>302</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>303</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>304</td>\n      <td>0.003600</td>\n    </tr>\n    <tr>\n      <td>305</td>\n      <td>0.002800</td>\n    </tr>\n    <tr>\n      <td>306</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>307</td>\n      <td>0.002000</td>\n    </tr>\n    <tr>\n      <td>308</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>309</td>\n      <td>0.002800</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>311</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>312</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>313</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>314</td>\n      <td>0.003300</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>316</td>\n      <td>0.002200</td>\n    </tr>\n    <tr>\n      <td>317</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>318</td>\n      <td>0.002700</td>\n    </tr>\n    <tr>\n      <td>319</td>\n      <td>0.003000</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <td>321</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>322</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <td>323</td>\n      <td>0.004400</td>\n    </tr>\n    <tr>\n      <td>324</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>326</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>327</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>328</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>329</td>\n      <td>0.000900</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>331</td>\n      <td>0.002200</td>\n    </tr>\n    <tr>\n      <td>332</td>\n      <td>0.003300</td>\n    </tr>\n    <tr>\n      <td>333</td>\n      <td>0.002300</td>\n    </tr>\n    <tr>\n      <td>334</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>335</td>\n      <td>0.002600</td>\n    </tr>\n    <tr>\n      <td>336</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>337</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>338</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>339</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>341</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>342</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>343</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>344</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>346</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>347</td>\n      <td>0.001900</td>\n    </tr>\n    <tr>\n      <td>348</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>349</td>\n      <td>0.000900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.001000</td>\n    </tr>\n    <tr>\n      <td>351</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>352</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>353</td>\n      <td>0.000900</td>\n    </tr>\n    <tr>\n      <td>354</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>355</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>356</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>357</td>\n      <td>0.001100</td>\n    </tr>\n    <tr>\n      <td>358</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>359</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>361</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>362</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>363</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>364</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <td>365</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>366</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>367</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>368</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>369</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>371</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>372</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>373</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>374</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.001500</td>\n    </tr>\n    <tr>\n      <td>376</td>\n      <td>0.001500</td>\n    </tr>\n    <tr>\n      <td>377</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>378</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>379</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>381</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>382</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>383</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>384</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>385</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>386</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>387</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>388</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>389</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>391</td>\n      <td>0.000700</td>\n    </tr>\n    <tr>\n      <td>392</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>393</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>394</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>396</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>397</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>398</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>399</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>401</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>402</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>403</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>404</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>406</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>407</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>408</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>409</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>411</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>412</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>413</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>414</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>415</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>416</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>417</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>418</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>419</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>421</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>422</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>423</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>424</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>426</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>427</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>428</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>429</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>431</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>432</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>433</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>434</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>436</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>437</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>438</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>439</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>441</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>442</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>443</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>444</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>445</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>446</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>447</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>448</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>449</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>451</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>452</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>453</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>454</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>455</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>456</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>457</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>458</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>459</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>461</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>462</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>463</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>464</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>465</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>466</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>467</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>468</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>469</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>471</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>472</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>473</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>474</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>476</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>477</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>478</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>479</td>\n      <td>0.000500</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>481</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>482</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>483</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>484</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>485</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>486</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>487</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>488</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>489</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>491</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>492</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>493</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>494</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>495</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>496</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>497</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>498</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>499</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>501</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>502</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>503</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>504</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>505</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>506</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>507</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>508</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>509</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>511</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>512</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>513</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>514</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>515</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>516</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>517</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>518</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>519</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>521</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>522</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>523</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>524</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>526</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>527</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>528</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>529</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>531</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>532</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>533</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>534</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>535</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>536</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>537</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>538</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>539</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>541</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>542</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>543</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>544</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>545</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>546</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>547</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>548</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>549</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>551</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>552</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>553</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>554</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>555</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>556</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>557</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>558</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>559</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>561</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>562</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>563</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>564</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>565</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>566</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>567</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>568</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>569</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>571</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>572</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>573</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>574</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>576</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>577</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>578</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>579</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>581</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>582</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>583</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>584</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>585</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>586</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>587</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>588</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>589</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>591</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>592</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>593</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>594</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>595</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>596</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>597</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>598</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>599</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>601</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>602</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>603</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>604</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>605</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>606</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>607</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>608</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>609</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>611</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>612</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>613</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>614</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>615</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>616</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>617</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>618</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>619</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>621</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>622</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>623</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>624</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>626</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>627</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>628</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>629</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>631</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>632</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>633</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>634</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>635</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>636</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>637</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>638</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>639</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>641</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>642</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>643</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>644</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>645</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>646</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>647</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>648</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>649</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>651</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>652</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>653</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>654</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>655</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>656</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>657</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>658</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>659</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>661</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>662</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>663</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>664</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>665</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>666</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>667</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>668</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>669</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>671</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>672</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>673</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>674</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>676</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>677</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>678</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>679</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>681</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>682</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>683</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>684</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>685</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>686</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>687</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>688</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>689</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>691</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>692</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>693</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>694</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>695</td>\n      <td>0.000200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract the training losses from the log history\nlosses = [log[\"loss\"] for log in trainer.state.log_history if \"loss\" in log]\n\n# Create the figure with larger size\nplt.figure(figsize=(12, 8))  # Adjust the width and height (in inches)\n\n# Plotting the loss curve\nplt.plot(losses)\n\n# Adding a heading for the figure\nplt.suptitle(\"Llama-3.2-1b r=16\", fontsize=20, fontweight='bold')\n\n# Adding the title, axis labels, and displaying the plot\nplt.title(\"Training Loss\", fontsize=16)\nplt.xlabel(\"Steps\", fontsize=10)\nplt.ylabel(\"Loss\", fontsize=10)\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:16:27.252135Z","iopub.execute_input":"2024-11-17T06:16:27.252524Z","iopub.status.idle":"2024-11-17T06:16:27.573114Z","shell.execute_reply.started":"2024-11-17T06:16:27.252485Z","shell.execute_reply":"2024-11-17T06:16:27.572152Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:09:22.211142Z","iopub.execute_input":"2024-11-17T06:09:22.211527Z","iopub.status.idle":"2024-11-17T06:09:22.219240Z","shell.execute_reply.started":"2024-11-17T06:09:22.211489Z","shell.execute_reply":"2024-11-17T06:09:22.218279Z"}},"outputs":[{"name":"stdout","text":"13974.5454 seconds used for training.\n232.91 minutes used for training.\nPeak reserved memory = 9.113 GB.\nPeak reserved memory for training = 6.478 GB.\nPeak reserved memory % of max memory = 61.821 %.\nPeak reserved memory for training % of max memory = 43.945 %.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Dr. Nishat Afshan Ansari\"},\n]\ninputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\noutputs = model.generate(input_ids = inputs, max_new_tokens = 2000, use_cache = True,\n                         temperature = 0.1, min_p = 0.1)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2024-11-17T06:03:30.356049Z","shell.execute_reply.started":"2024-11-17T06:03:04.588563Z","shell.execute_reply":"2024-11-17T06:03:30.355074Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nDr. Nishat Afshan Ansari<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{\\n\"name\": \"Dr. Nishat Afshan Ansari\",\\n\"department\": \"Computer Science and Engineering\",\\n\"position\": \"Chairman/Head of Department\",\\n\"phone_no\": \"9766223703\",\\n\"email\": \"nishat.ansari@iiitn.ac.in\",\\n\"joining_date\": \"July 2019\",\\n\"education\": [\\n{\\n\"degree_year\": \"2009\",\\n\"college_name\": \"Visvesvaraya National Institute of Technology\",\\n\"university\": \"Visvesvaraya National Institute of Technology\",\\n\"degree\": \"M.Tech.\",\\n\"specialization\": \"CSE\"\\n},\\n{\\n\"degree_year\": \"NA\",\\n\"college_name\": \"Goverment College of Engineering Amravati\",\\n\"university\": \"NA\",\\n\"degree\": \"B.E.\",\\n\"specialization\": \"CSE\"\\n}\\n],\\n\"teaching_experience\": [\\n{\\n\"institution\": \"Indian Institute of Information Technology Nagpur\",\"position\": \"Assistant Professor\",\\n\"start_date\": \"July 2019\",\\n\"end_date\": \"Present\"\\n},\\n{\\n\"institution\": \"RCOEM, Nagpur\",\\n\"position\": \"Assistant Professor\",\\n\"start_date\": \"Jun 2009\",\\n\"end_date\": \"Oct 2022\"\\n}\\n],\\n\"industrial_experience\": [],\\n\"laboratory_development\": [],\\n\"areas_of_interest\": [],\\n\"projects\": [],\\n\"publications\": {\\n\"0\": \"An acoustic analysis of speech for emotion recognition using deep\\nlearning\",\\n\"1\": \"Deep learning based authentication schemes for smart devices in different\\nmodalities: progress, challenges, performance, datasets and future directions\",\\n\"2\": \"An asynchronous algorithm for providing energy efficient coverage and\\nconnectivity in Wireless Sensor Networks\",\\n\"3\": \"A distributed algorithm for object tracking in wireless sensor networks\\nusing data mining based predicition\",\\n\"4\": \"Generative AI for Text to Image: A Comprehensive Survey\",\\n\"5\": \"A Novel Technique for Performing Tiger Census in a Forest Using WirelessMultimedia Sensor Networks.\",\\n\"6\": \"A fault tolerant algorithm for integrated coverage and connectivity in\\nwireless sensor networks\"\\n},\\n\"supervision\": [],\\n\"fellowships\": []\\n}<|eot_id|>']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Phd admission details\"},\n]\ninputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\n_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 2000,\n                   use_cache = True, temperature = 0.5, min_p = 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:03:30.357198Z","iopub.execute_input":"2024-11-17T06:03:30.357507Z","iopub.status.idle":"2024-11-17T06:04:29.931044Z","shell.execute_reply.started":"2024-11-17T06:03:30.357472Z","shell.execute_reply":"2024-11-17T06:04:29.930065Z"}},"outputs":[{"name":"stdout","text":"{\n\"PhD_Program\": {\n\"Categories\": {\n\"Industry_Candidates\": [\n{\n\"Type\": \"Extern\",\n\"Code\": \"EX-I\",\n\"Description\": \"Extern Candidate from Industry\"\n},\n{\n\"Type\": \"Intern\",\n\"Code\": \"IN-IS\",\n\"Description\": \"Intern Sponsored Candidate from Industry\"\n}\n],\n\"Academic_Institution_Candidates\": [\n{\n\"Type\": \"Extern\",\n\"Code\": \"EX-A\",\n\"Description\": \"Self-financed Candidate from Academic Institutions\"\n},\n{\n\"Type\": \"Intern\",\n\"Code\": \"IN-AS\",\n\"Description\": \"Intern Sponsored Candidate from Academic Institutions\"\n}],\n\"Other_Candidates\": [\n{\n\"Type\": \"Intern\",\n\"Code\": \"IN-U\",\n\"Description\": \"Intern Self-Sponsored Candidate\"\n},\n{\n\"Type\": \"Intern\",\n\"Code\": \"IN-ES\",\n\"Description\": \"Intern externally funded or Project Staff Candidate\"\n}\n]\n},\n\"Regulations\": \"The Ph.D. program operates under the Academic Regulations of the\nInstitute. Refer to the PhD Rule Book for academic regulations and details.\",\n\"Admission_Modality\": {\n\"Description\": \"Focuses on IT Industry problems, fostering Industry-Academia\n\"Rejection_Criteria\": \"Applications not in prescribed form, lacking enclosures,\nreceived late, or without fees will be rejected. No interim correspondence\nentertained.\",\n\"Postal_Delay\": \"Institute not responsible for postal delays or loss.\"\n},\n\"Examination_Pattern\": {\n\"Entrance_Test\": {\n\"Sections\": [\n{\n\"Section\": 1,\n\"Content\": \"General Ability and Communication Skills\",\n\"Common_For\": \"All Categories\"\n},\n{\n\"Section\": 2,\n\"Syllabus\": {\n\"Industry_Candidates\": {\n\"Categories\": [\n\"EX-I\",\n\"IN-IS\"\n],\n\"Content\": [\n\"Basic Engineering Maths\",\"Basic Programming and Engineering Knowledge\",\n\"Engineering Logical Analysis\",\n\"Arithmetic\",\n\"Industry Standards\"\n]\n},\n\"Remaining_Candidates\": {\n\"Categories\": [\n\"EX-A\",\n\"IN-AS\",\n\"IN-U\",\n\"IN-ES\"\n],\n\"Streams\": {\n\"Electronics_and_Communication_Engineering\": [\n\"Engineering Mathematics\",\n\"Networks\",\n\"Signals and Systems\",\n\"Electronic Devices\",\n\"Analog Circuits\",\n\"Digital Circuits\",\n\"Control Systems\",\n\"Communications\",\n\"Electromagnetic\"\n],\n\"Computer_Science_and_Engineering_Information_Technology\": [\"Engineering Mathematics\",\n\"Digital Logic\",\n\"Computer Organization and Architecture\",\n\"Programming and Data Structures\",\n\"Algorithms\",\n\"Theory of Computation\",\n\"Compiler Design\",\n\"Operating System\",\n\"Databases\",\n\"Computer Networks\"\n]\n}\n}\n}\n}\n]\n},\n\"SoP_Presentation\": {\n\"Requirements\": [\n{\n\"Requirement\": \"Attach SoP in the specified format (Annexure-2) to both soft\nand hard copies of the application.\"\n},\n{\n\"Requirement\": \"Industry Candidates (EX-I/IN-IS) must prepare a 5-slide\npresentation on intended research problems for the interview.\"}\n]\n}\n},\n\"Selection_Process\": {\n\"Stages\": [\n{\n\"Stage\": 1,\n\"Name\": \"Entrance Test\",\n\"Description\": \"Eligible candidates appear physically for the Entrance Test at\nthe Institute's Permanent Campus.\",\n\"Qualifying_Score\": \"Normalized minimum score of 40% (based on top score\nnormalization).\"\n},\n{\n\"Stage\": 2,\n\"Name\": \"Interview\",\n\"Description\": \"Candidates qualifying the Entrance Test attend an offline\npersonal interview.\"\n},\n{\n\"Stage\": 3,\n\"Name\": \"Combined Score Calculation\",\n\"Description\": \"Final selection based on scores from Entrance Test, Interview,\nand GATE qualification.\"\n}],\n\"Weightage_Distribution\": {\n\"EX-I_IN-IS\": {\n\"Total_Marks\": 100,\n\"Entrance_Test\": 40,\n\"Interview\": 50,\n\"GATE_Qualification\": 10\n},\n\"EX-A_IN-AS_IN-U_IN-ES\": {\n\"Total_Marks\": 100,\n\"Entrance_Test\": 40,\n\"Interview\": 50,\n\"GATE_Qualification\": 10\n}\n}\n},\n\"PhD_Duration\": {\n\"Default\": \"3 years from the date of joining until thesis submission for EX-A,\nIN-AS, IN-U, IN-ES categories.\",\n\"Industry_Candidates\": {\n\"With_Masters\": \"3 years\",\n\"With_Bachelors\": \"4 years\"\n}\n}\n}\n}<|eot_id|>\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.save_pretrained(\"lora_model\") # Local saving\ntokenizer.save_pretrained(\"lora_model\")\n# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:04:29.932559Z","iopub.execute_input":"2024-11-17T06:04:29.933256Z","iopub.status.idle":"2024-11-17T06:04:30.868121Z","shell.execute_reply.started":"2024-11-17T06:04:29.933209Z","shell.execute_reply":"2024-11-17T06:04:30.867189Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('lora_model/tokenizer_config.json',\n 'lora_model/special_tokens_map.json',\n 'lora_model/tokenizer.json')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"if False:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nimport time\nmessages = [\n    {\"role\": \"user\", \"content\": \"Give me timetable of Lab2\"},\n]\ninputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")\nprint(\"Give me timetable of Lab2\")\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\nstart_time = time.time()\n_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 1000,\n                   use_cache = True, temperature = 0.1, min_p = 0.1)\nend_time = time.time()\nresponse_time = end_time - start_time\nprint(f\"Response time: {response_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:09:54.396838Z","iopub.execute_input":"2024-11-17T06:09:54.397758Z","iopub.status.idle":"2024-11-17T06:09:59.339527Z","shell.execute_reply.started":"2024-11-17T06:09:54.397712Z","shell.execute_reply":"2024-11-17T06:09:59.338635Z"}},"outputs":[{"name":"stdout","text":"Give me timetable of Lab2\n{\n\"lab_name\": \"Lab2\",\n\"schedule\": {\n\"monday\": {},\n\"tuesday\": {},\n\"wednesday\": {\n\"14-16\": \"DBMS Lab-CSE-A2-V\"\n},\n\"thursday\": {\n\"14-16\": \"OOPS Lab-CSE-HCI-B2-III\"\n},\n\"friday\": {}\n},\n\"additional_info\": {}\n}<|eot_id|>\nResponse time: 4.93 seconds\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"df.iloc[186][\"conversations\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:21:50.447901Z","iopub.execute_input":"2024-11-17T06:21:50.448533Z","iopub.status.idle":"2024-11-17T06:21:50.456943Z","shell.execute_reply.started":"2024-11-17T06:21:50.448480Z","shell.execute_reply":"2024-11-17T06:21:50.455832Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[{'from': 'human', 'value': 'timetable- Lab2'},\n {'from': 'gpt',\n  'value': '{\\n\"lab_name\": \"Lab2\",\\n\"schedule\": {\\n\"monday\": {},\\n\"tuesday\": {},\\n\"wednesday\": {\\n\"14-16\": \"DBMS Lab-CSE-A2-V\"\\n},\\n\"thursday\": {\\n\"14-16\": \"OOPS Lab-CSE-HCI-B2-III\"\\n},\\n\"friday\": {}\\n},\\n\"additional_info\": {}\\n}'}]"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}